{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tratamento de image",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aleyucra74/Colab-google-MLP-OCR/blob/main/tratamento_de_image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kyTsZu85yj-"
      },
      "source": [
        "Ideia número 1:\n",
        "Reconhecimento por palavras do município\n",
        "\n",
        "Passos: Leitura do pdf pelo OpenCV, tirando foto do cabeçalho \n",
        "\n",
        "Leitura do pytesseract das palavras dessa foto, salvando em tuplas esse conteúdo já com o nome do município para treino\n",
        "\n",
        "Organizar essa base e colocar no lugar dos arquivos train, validation, test conforme já tem exemplo.\n",
        "\n",
        "Utilizar modelo ML Perceptron no exemplo  \n",
        "\n",
        "Avaliar acurácia (A meta é 50~75%)\n",
        "\n",
        "Colocar modelo em operação com função joblib\n",
        "\n",
        "Ideia número 2:\n",
        "\n",
        "Não usar machine learning, e sim a função thefuzz que agrupa palavras parecidas.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZT9VGPsjZSb"
      },
      "source": [
        "#instalando tesseract\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract pdf2image thefuzz poppler-utils PyMuPDF==1.18.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmuOKwOllnwo"
      },
      "source": [
        "# usando opencv , tesseract , thefuzz\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import re\n",
        "from thefuzz import fuzz\n",
        "from thefuzz import process\n",
        "import fitz\n",
        "\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PxcI_Let3h8"
      },
      "source": [
        "#############################################\n",
        "# SOMENTE DEPOIS (gpu para acelerar processamento)\n",
        "#############################################\n",
        "# from h2o4gpu.model_selection import train_test_split\n",
        "# from h2o4gpu.neural_network import MLPClassifier\n",
        "# from h2o4gpu.preprocessing import StandardScaler\n",
        "# from h2o4gpu.metrics import mean_squared_error, confusion_matrix, accuracy_score, precision_score, recall_score\n",
        "#############################################\n",
        "\n",
        "#Importando a técnica Multi Layer Perceptron do Sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, confusion_matrix, accuracy_score, precision_score, recall_score\n",
        "from matplotlib import pyplot as plt\n",
        "from collections import defaultdict\n",
        "from datetime import datetime\n",
        "import multiprocessing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import cudf \n",
        "import cupy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOe3Sz_FjbKk"
      },
      "source": [
        "#lendo palavras do pdf>imagem>palavras (opção 1)\n",
        "def proc():\n",
        "    main_text = ''\n",
        "    for imgn in os.listdir('imgs'):\n",
        "        img = cv2.imread(f'imgs/{imgn}')\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        file = f'grays\\{imgn}.png'\n",
        "        cv2.imwrite(file,gray)\n",
        "        text=pytesseract.image_to_string(Image.open(file))\n",
        "        main_text += text.replace('\\n', '') + '\\n'\n",
        "    return main_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4cPwvDrk-ab"
      },
      "source": [
        "#lendo palavras do pdf>imagem>palavras (opção 2) (testar)\n",
        "def proc():\n",
        "    main_text = ''\n",
        "    for imgn in os.listdir('imgs'):\n",
        "        img = cv2.imread(f'imgs/{imgn}')\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        text=pytesseract.image_to_string(gray)\n",
        "        main_text += text.replace('\\n', '') + '\\n'\n",
        "    return main_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBf_5QiZoTNz"
      },
      "source": [
        "#demonstração de como cortar pedaço do pdf (cabeçalho)\n",
        "# from google.colab.patches import cv2_imshow # para visualizar imagem\n",
        "def proc(imgn):\n",
        "    img = cv2.imread(f'{imgn}')\n",
        "    # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    crop_img1 = img[25:73, 250:843].copy()\n",
        "    crop_img2 = img[10:170,20:230].copy() \n",
        "    # cv2_imshow(crop_img1) # para visualizar o corte \n",
        "    # cv2_imshow(crop_img2)\n",
        "    text=pytesseract.image_to_string(crop_img1).replace('\\n', '')\n",
        "    return [text, crop_img2] # retorna texto encontrado e imagem do brazão"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo5zKq3AaHol"
      },
      "source": [
        "#demonstração de tratamento do pdf para o tesseract ler melhor\n",
        "def convert_pdf2img(input_file: str, pages:tuple = None):\n",
        "    if not os.path.isdir('pasta_pdf'): os.mkdir('pasta_pdf')\n",
        "    \"\"\"Converts pdf to image and generates a file by page\"\"\"\n",
        "    # Open the document\n",
        "    pdfIn = fitz.open(input_file)\n",
        "    output_files = []\n",
        "    # Iterate throughout the pages\n",
        "    for pg in range(pdfIn.pageCount):\n",
        "        if pages is not None:\n",
        "            if str(pg) not in str(pages):\n",
        "                continue\n",
        "        # Select a page\n",
        "        page = pdfIn[pg]\n",
        "        rotate = int(0)\n",
        "        # PDF Page is converted into a whole picture 1056*816 and then for each picture a screenshot is taken.\n",
        "        # zoom = 1.33333333 -----> Image size = 1056*816\n",
        "        # zoom = 2 ---> 2 * Default Resolution (text is clear, image text is hard to read)    = filesize small / Image size = 1584*1224\n",
        "        # zoom = 4 ---> 4 * Default Resolution (text is clear, image text is barely readable) = filesize large\n",
        "        # zoom = 8 ---> 8 * Default Resolution (text is clear, image text is readable) = filesize large\n",
        "        zoom_x = 2\n",
        "        zoom_y = 2\n",
        "        # The zoom factor is equal to 2 in order to make text clear\n",
        "        # Pre-rotate is to rotate if needed.\n",
        "        mat = fitz.Matrix(zoom_x, zoom_y).preRotate(rotate)\n",
        "        pix = page.getPixmap(matrix=mat, alpha=False)\n",
        "        output_file = f\"pasta_pdf/{os.path.splitext(os.path.basename(input_file))[0]}_page{pg+1}.png\"\n",
        "        \n",
        "        pix.writePNG(output_file)\n",
        "        \n",
        "        output_files.append(output_file)\n",
        "    pdfIn.close()\n",
        "    summary = {\n",
        "        \"File\": input_file, \"Pages\": str(pages), \"Output File(s)\": str(output_files)\n",
        "    }\n",
        "    # Printing Summary\n",
        "    print(\"## Summary ########################################################\")\n",
        "    print(\"\\n\".join(\"{}:{}\".format(i, j) for i, j in summary.items()))\n",
        "    print(\"###################################################################\")\n",
        "    return output_files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ7a2wtCosl1"
      },
      "source": [
        "# demonstração importando pasta inteira de notas \n",
        "textos = {}\n",
        "for pdf in listdir('pasta_pdf'):\n",
        "  img_pdf = convert_pdf2img(pdf)\n",
        "  for imagem in img_pdf:\n",
        "    textos[imagem] = proc(imagem)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNmdrE5WpL8Z"
      },
      "source": [
        "#demonstração de como salvar as palavras e as classes (municipios)\n",
        "\n",
        "# palvras palaavras sao paulo palavras | classe1\n",
        "# palvras palaavras sao paulo palavras | classe1\n",
        "# palvras palaavras sao paulo palavras | classe1\n",
        "# Treino 70% ~ 85% das notas \n",
        "# Teste 30% ~ 15% das notas\n",
        "# (76% train - 12% validation - 12% test)\n",
        "\n",
        "esperado = array_de_classes\n",
        "treino = array_de_textos\n",
        "\n",
        "teste = array_de_textos_teste\n",
        "validacao = array_de_classes_teste"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDGck1QGro2N"
      },
      "source": [
        "#Modelo Multi Layer Perceptron\n",
        "\n",
        "mlp = MLPClassifier(solver='lbfgs', alpha=0.001, max_iter=10000, hidden_layer_sizes=(1,2,3), learning_rate='adaptive')\n",
        "mlp.fit(treino, esperado) # treina\n",
        "\n",
        "output = mlp.predict(teste) # testa e classifica\n",
        "\n",
        "mmlp['linhas_prc'].append(linhas)\n",
        "mmlp['iteracao'].append((1,2,3)))\n",
        "mmlp['precisao'].append(precision_score(validacao, output ))\n",
        "mmlp['acuracia'].append(accuracy_score(validacao, output, normalize=False))\n",
        "mmlp['acuracia_percent'].append(accuracy_score(validacao, output, normalize=False)/len(validacao))\n",
        "mmlp['mse'].append(mean_squared_error(validacao, output))\n",
        "mmlp['iters_to_fit'].append(mlp.n_iter_)\n",
        "mmlp['matriz_confusao'].append(confusion_matrix(validacao, output))\n",
        "mmlp['recal'].append(recall_score(validacao, output))\n",
        "print('acuracia:', round(accuracy_score(validacao, output, normalize=False)/len(validacao), 4), '| precisao:', round(precision_score(validacao, output), 4), '| Recal:', round(recall_score(validacao, output), 4), '| mse:', round(mean_squared_error(validacao, output), 4), '| MLP:', ll, '| Tempo:', datetime.now()-dt1, '| ds:', nome_output, '| Iters:', mlp.n_iter_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjZbkxMTr5x6"
      },
      "source": [
        "#depois de validado o modelo, chama ele para classificação de outras notas\n",
        "joblib.dump(last_mlp, nome_output + '.pkl', compress=7) # exporta o modelo treinado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN5tiOj2ByzT"
      },
      "source": [
        "Ideia 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DW2Yg6jlPqU",
        "outputId": "7b495ce8-1135-4b1b-c2cc-51d1bccb683d"
      },
      "source": [
        "#demonstração da lógica fuzz \n",
        "fuzz.ratio(\"so palo\", \"São Paulo\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGwdjhTqC2FP"
      },
      "source": [
        "Ideia 3\n",
        "\n",
        "Fazer reconhecimento apenas por imagem do brasão da cidade"
      ]
    }
  ]
}